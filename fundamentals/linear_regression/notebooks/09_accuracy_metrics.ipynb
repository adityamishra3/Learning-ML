{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a07e3c1",
   "metadata": {},
   "source": [
    "# Regression Metrics\n",
    "\n",
    "1. MAE \n",
    "2. MSE\n",
    "3. RMSE\n",
    "4. R2 Score\n",
    "5. Adjusted R2 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196eecf4",
   "metadata": {},
   "source": [
    "## 1. MAE (Mean absolute error)\n",
    "\n",
    "Mean of absolute error, i.e. we will calculate absoulte error (mod of the error to keep it positive) for each data point and calculate its mean\n",
    "\n",
    "$$\n",
    "mae = \\frac{\\sum_{i=1}^m |{y_i} - {\\hat{y}_i} |}{m}\n",
    "$$\n",
    "\n",
    "#### Advantage:\n",
    "1. mae is exactly in the unit of y (LPA in salary, 100,000 in housing price)\n",
    "2. Mae is robust to outliers (relatively less affected by outliers)\n",
    "\n",
    "#### Disadvantage:\n",
    "\n",
    "1. Non-differentiable at zero residual\n",
    "\n",
    "    The absolute value function has a sharp corner at zero, so its derivative is undefined at that point. While practical implementations use subgradients and do not crash, the loss surface is not smooth. This can lead to slower or less stable convergence in gradient-based optimization compared to smooth losses like MSE.\n",
    "\n",
    "2. Constant gradient magnitude\n",
    "\n",
    "    The gradient of MAE depends only on the sign of the error, not its magnitude. As a result, the gradient does not decrease as the model approaches the minimum. This can cause oscillations near the optimum and slower convergence compared to MSE.\n",
    "\n",
    "3. Less penalization of large errors\n",
    "\n",
    "    Since errors are not squared, large residuals are penalized linearly. This makes MAE robust to outliers but reduces the incentive for the model to aggressively correct very large mistakes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20816bc",
   "metadata": {},
   "source": [
    "## 2. MSE (Mean Squared Error)\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "MSE calculates the average of the squared differences between actual and predicted values.\n",
    "\n",
    "\n",
    "---\n",
    "### Example:\n",
    "\n",
    "If the true salary is **6 LPA** and the predicted salary is **12 LPA**, then:\n",
    "\n",
    "Error = ( 6 )\n",
    "\n",
    "Squared Error = ( 6^2 = 36 )\n",
    "\n",
    "So the contribution to MSE is **36 (LPA²)**.\n",
    "\n",
    "Notice that the unit becomes **squared**, which makes interpretation less intuitive.\n",
    "\n",
    "\n",
    "\n",
    "### Advantages\n",
    "\n",
    "1. **Smooth and fully differentiable**\n",
    "\n",
    "   MSE is based on a quadratic function, which is differentiable everywhere with continuous gradients. This makes it highly suitable for gradient-based optimization methods like gradient descent. As the error approaches zero, the gradient smoothly decreases to zero, enabling stable convergence.\n",
    "\n",
    "2. **Strongly penalizes large errors**\n",
    "\n",
    "   Since errors are squared, large residuals grow rapidly.\n",
    "   For example:\n",
    "\n",
    "   * Error = 2 → Squared = 4\n",
    "   * Error = 10 → Squared = 100\n",
    "   * Error = 50 → Squared = 2500\n",
    "\n",
    "   This forces the model to prioritize correcting large mistakes.\n",
    "\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "1. **Less interpretable**\n",
    "\n",
    "   The loss is expressed in squared units of the target variable (e.g., LPA²), which makes it harder to interpret directly compared to MAE.\n",
    "\n",
    "2. **Sensitive to outliers**\n",
    "\n",
    "   Because large errors are amplified quadratically, even a single outlier can significantly increase the loss and heavily influence the model. Therefore, MSE is not robust to outliers.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069f62e",
   "metadata": {},
   "source": [
    "\n",
    "## RMSE (Root Mean Squared Error)\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "\n",
    "RMSE is simply the square root of the Mean Squared Error.\n",
    "\n",
    "---\n",
    "\n",
    "### Example\n",
    "\n",
    "If the true salary is **6 LPA** and the predicted salary is **12 LPA**, then:\n",
    "\n",
    "Error = ( 6 )\n",
    "\n",
    "Squared Error = ( 6^2 = 36 )\n",
    "\n",
    "MSE contribution = 36\n",
    "\n",
    "RMSE = ( \\sqrt{36} = 6 )\n",
    "\n",
    "Notice that RMSE brings the loss back to the **same unit as the target variable (LPA)**, making it easier to interpret compared to MSE.\n",
    "\n",
    "---\n",
    "\n",
    "### Properties\n",
    "\n",
    "RMSE retains all mathematical properties of MSE because it is directly derived from it.\n",
    "\n",
    "---\n",
    "\n",
    "### Advantages\n",
    "\n",
    "1. **Interpretable unit**\n",
    "\n",
    "   Unlike MSE, RMSE is expressed in the same unit as the target variable, making it more intuitive to understand.\n",
    "\n",
    "2. **Smooth and differentiable**\n",
    "\n",
    "   Since it is derived from MSE, it remains differentiable and suitable for gradient-based optimization.\n",
    "\n",
    "---\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "1. **Sensitive to outliers**\n",
    "\n",
    "   Because it is based on squared errors, large residuals are still heavily penalized. Therefore, RMSE is not robust to outliers.\n",
    "\n",
    "2. **Still influenced by large errors**\n",
    "\n",
    "   Although the square root reduces the scale, the underlying squaring effect still gives higher weight to large mistakes compared to MAE.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ec8128",
   "metadata": {},
   "source": [
    "## R² Score (Coefficient of Determination)\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "SS_{res} = \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "SS_{tot} = \\sum_{i=1}^{m} (y_i - \\bar{y})^2\n",
    "$$\n",
    "\n",
    "* $ {SS_{res}} $ → Residual Sum of Squares (SSE of regression model)\n",
    "* $ {SS_{tot}} $→ Total Sum of Squares (SSE of predicting the mean)\n",
    "* $ {\\bar{y} }$ → Mean of actual target values\n",
    "\n",
    "---\n",
    "\n",
    "### What is R²?\n",
    "\n",
    "R² measures how much variance in the target variable is explained by the model compared to simply predicting the mean.\n",
    "\n",
    "It compares:\n",
    "\n",
    "* Error made by your regression model\n",
    "  vs\n",
    "* Error made by a naive model that always predicts the mean\n",
    "\n",
    "So it tells us how much better our model is than just using the average.\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation of R²\n",
    "\n",
    "#### 1️⃣ If R² = 0\n",
    "\n",
    "$$\n",
    "SS_{res} = SS_{tot}\n",
    "$$\n",
    "\n",
    "This means:\n",
    "\n",
    "Your regression model performs exactly the same as predicting the mean.\n",
    "\n",
    "In other words:\n",
    "\n",
    "* The regression line is effectively behaving like the mean line.\n",
    "* The features are not helping.\n",
    "* The model is not learning any useful relationship.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2️⃣ If R² = 1\n",
    "\n",
    "$$\n",
    "SS_{res} = 0\n",
    "$$\n",
    "\n",
    "This means:\n",
    "\n",
    "* Predictions are perfectly equal to actual values.\n",
    "* There is no residual error.\n",
    "* The regression line fits all data points exactly.\n",
    "\n",
    "Since the numerator becomes 0:\n",
    "$$\n",
    "R^2 = 1 - 0 = 1\n",
    "$$\n",
    "\n",
    "This represents a perfect fit.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3️⃣ If R² is Between 0 and 1\n",
    "\n",
    "Example:\n",
    "\n",
    "R² = 0.75\n",
    "\n",
    "This means:\n",
    "\n",
    "75% of the variance in the target variable is explained by the model, and 25% remains unexplained.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4️⃣ If R² is Negative\n",
    "\n",
    "This happens when:\n",
    "\n",
    "$$\n",
    "SS_{res} > SS_{tot}\n",
    "$$\n",
    "\n",
    "Meaning:\n",
    "\n",
    "The model performs worse than simply predicting the mean.\n",
    "\n",
    "This can happen when:\n",
    "\n",
    "* The model is poorly trained\n",
    "* The wrong features are used\n",
    "* There is severe overfitting on training data\n",
    "\n",
    "---\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "* R² does **not** measure prediction accuracy directly.\n",
    "* It measures how much variance is explained relative to a baseline (mean model).\n",
    "* Higher R² does not always mean better model — especially in overfitting scenarios.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f8901e",
   "metadata": {},
   "source": [
    "## Adjusted R²\n",
    "\n",
    "Adjusted R² is a modified version of R² that accounts for the number of features in the model.\n",
    "\n",
    "While R² **never decreases** when you add more features (even useless ones), Adjusted R² increases **only if the new feature actually improves the model more than would be expected by chance**.\n",
    "\n",
    "---\n",
    "\n",
    "### Why is Adjusted R² Used?\n",
    "\n",
    "Because R² can be misleading when comparing models with different numbers of features.\n",
    "\n",
    "When you add a new column:\n",
    "\n",
    "* R² will either increase or stay the same.\n",
    "* It never penalizes complexity.\n",
    "\n",
    "Adjusted R² introduces a penalty for adding unnecessary features.\n",
    "\n",
    "So it helps answer:\n",
    "\n",
    "> Is this new feature genuinely improving the model, or just artificially inflating R²?\n",
    "\n",
    "---\n",
    "\n",
    "### Example 1 — Useless Feature (R² Increases, Adjusted R² Decreases)\n",
    "\n",
    "Suppose you are predicting salary using:\n",
    "\n",
    "* Years of experience\n",
    "* Education level\n",
    "\n",
    "Model performance:\n",
    "\n",
    "* R² = 0.78\n",
    "* Adjusted R² = 0.77\n",
    "\n",
    "Now you add a random column:\n",
    "\n",
    "* Employee ID number (which has no logical relationship with salary)\n",
    "\n",
    "After retraining:\n",
    "\n",
    "* R² = 0.79 (it increased slightly)\n",
    "* Adjusted R² = 0.75 (it decreased)\n",
    "\n",
    "Why?\n",
    "\n",
    "Because R² only checks whether the residual error decreased.\n",
    "Even random noise can slightly reduce error due to chance.\n",
    "\n",
    "But Adjusted R² detects that this improvement is not statistically meaningful and penalizes the model for unnecessary complexity.\n",
    "\n",
    "So in this case:\n",
    "\n",
    "* R² suggests improvement.\n",
    "* Adjusted R² correctly signals overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### Example 2 — Useful Feature (Both Increase)\n",
    "\n",
    "Same original model:\n",
    "\n",
    "* R² = 0.78\n",
    "* Adjusted R² = 0.77\n",
    "\n",
    "Now you add:\n",
    "\n",
    "* Skill certification score (which genuinely affects salary)\n",
    "\n",
    "After retraining:\n",
    "\n",
    "* R² = 0.85\n",
    "* Adjusted R² = 0.84\n",
    "\n",
    "Here:\n",
    "\n",
    "* Error decreases significantly.\n",
    "* The new feature explains additional variance.\n",
    "* Adjusted R² increases because the improvement justifies the added complexity.\n",
    "\n",
    "---\n",
    "\n",
    "### When Adjusted R² Is Not Very Useful\n",
    "\n",
    "Adjusted R² is less useful when:\n",
    "\n",
    "* You are not comparing models with different numbers of features.\n",
    "* You care more about predictive performance on unseen data (where cross-validation is better).\n",
    "* You are using non-linear or non-parametric models (like decision trees or neural networks).\n",
    "\n",
    "In modern ML workflows, validation metrics often matter more than Adjusted R².\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaway\n",
    "\n",
    "* R² measures how much variance is explained.\n",
    "* R² always increases when you add features.\n",
    "* Adjusted R² increases only if the new feature adds real explanatory power.\n",
    "* It is mainly used for comparing multiple regression models with different numbers of predictors.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33933ab",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
