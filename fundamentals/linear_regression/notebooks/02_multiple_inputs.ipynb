{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "069c044e",
   "metadata": {},
   "source": [
    "### This is the implementation of linear regression with multiple features as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204ed155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2520b3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  MedHouseVal  \n",
      "0    -122.23        4.526  \n",
      "1    -122.22        3.585  \n",
      "2    -122.24        3.521  \n",
      "3    -122.25        3.413  \n",
      "4    -122.25        3.422  \n"
     ]
    }
   ],
   "source": [
    "data = fetch_california_housing(as_frame=True)\n",
    "df = pd.DataFrame(data.frame) # using pandas to do data operations\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16c88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"MedHouseVal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3ffa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  \n",
      "0    -122.23  \n",
      "1    -122.22  \n",
      "2    -122.24  \n",
      "3    -122.25  \n",
      "4    -122.25  \n",
      "Index(['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup',\n",
      "       'Latitude', 'Longitude'],\n",
      "      dtype='object')\n",
      "----------\n",
      "0    4.526\n",
      "1    3.585\n",
      "2    3.521\n",
      "3    3.413\n",
      "4    3.422\n",
      "Name: MedHouseVal, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(columns=target_col)\n",
    "y = df[target_col]\n",
    "print(x.head())\n",
    "print(x.columns)\n",
    "print(\"-\"*10)\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe23de44",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "We‚Äôll use mean Standardization (standard scaling) because it plays nicest with gradient descent.\n",
    "\n",
    "Formula (this matters):\n",
    "\n",
    "$\n",
    "{x_{scaled}} = \\frac{x-\\mu}{\\sigma}\n",
    "$\n",
    "\n",
    "where $\\mu$ is the mean of a feature, and it helps us center all the data points around 0\n",
    "\n",
    "example:\n",
    "[2, 4, 6, 8]\n",
    "\n",
    "Mean:\n",
    "\n",
    "> Œº = (2 + 4 + 6 + 8) / 4 = 5\n",
    "\n",
    "Now subtract the mean from each value:\n",
    "\n",
    "x - Œº = [-3, -1, 1, 3]\n",
    "\n",
    "* Positive = above average\n",
    "\n",
    "* Negative = below average\n",
    "\n",
    "> This process is called mean centering\n",
    "\n",
    "#### Why mean-centering alone is insufficient\n",
    "\n",
    "Consider two features:\n",
    "```python\n",
    "Feature A (Income):    [-3, -1, 1, 3]\n",
    "Feature B (Population):[-3000, -1000, 1000, 3000]\n",
    "```\n",
    "\n",
    "Both are centered at 0, but‚Ä¶\n",
    "\n",
    "* Feature B is still 1000√ó larger\n",
    "\n",
    "* Gradients will still be dominated by Feature B\n",
    "\n",
    "So we fixed offset, not scale.\n",
    "\n",
    "#### What is standard deviation (œÉ)?\n",
    "\n",
    "Standard deviation answers ONE question:\n",
    "\n",
    "> ‚ÄúOn average, how far is a data point from the mean?‚Äù\n",
    "\n",
    "Think of it as spread or typical distance from normal.\n",
    "\n",
    "Intuition:\n",
    "\n",
    "* Low standard deviation = data points are clustered close to the mean\n",
    "\n",
    "* High standard deviation = data points are scattered far from the mean\n",
    "\n",
    "\n",
    "Lets continute from here:\n",
    "x - Œº = [-3, -1, 1, 3]\n",
    "\n",
    "standard deviation for the data points:\n",
    "\n",
    "$\\sigma = \\sqrt{\\frac{\\sum (x_i - \\mu)^2}{n}}$\n",
    "\n",
    "Let me break this down:\n",
    "\n",
    "1. Œº = mean (average) of all the data\n",
    "2. (x·µ¢ - Œº) = distance of each point from the mean\n",
    "3. (x·µ¢ - Œº)¬≤ = square each distance\n",
    "4. Œ£ = sum all those squared distances\n",
    "5. / n = divide by the number of data points (this gives you variance) - variance measure how much the data varies\n",
    "6. ‚àö = take the square root (this gives you standard deviation) - standard deviation means most points are within +/- $\\sigma$ of the mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82e0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing standard deviation:\n",
    "# formula: \n",
    "\n",
    "# def std(x):\n",
    "#     # step 1: find the mean:\n",
    "#     mu = np.mean(x)\n",
    "#     # step 2: distance of each point from the mean:\n",
    "#     x_mu = x - mu\n",
    "#     # step 3: squaring distance to avoid negatives, and so when we take average (while calculating variance), positive and negative dont cancel each other and we end with a 0.\n",
    "#     x_mu = x_mu ** 2 # squared each distance\n",
    "#     #step 4: (summation of squared distance and taking diving by n) basically mean haha, then we will get variance\n",
    "#     '''Variance = Mean of Squared Distances'''\n",
    "#     variance = np.mean(x_mu)\n",
    "#     std_dev = variance ** (1/2) # OR np.sqrt(variance)\n",
    "\n",
    "#     return std_dev\n",
    "\n",
    "# this implementation converts entire X (single or multiple feature into one standard deviation, but we need each std for each feature)\n",
    "# hence we use axis = 0, so that it returns an array of std, in which each value is std for individual columns\n",
    "def std(x):\n",
    "    # step 1: find the mean:\n",
    "    mu = np.mean(x, axis=0)\n",
    "    # step 2: distance of each point from the mean:\n",
    "    x_mu = x - mu\n",
    "    # step 3: squaring distance to avoid negatives, and so when we take average (while calculating variance), positive and negative dont cancel each other and we end with a 0.\n",
    "    x_mu = x_mu ** 2 # squared each distance\n",
    "    #step 4: (summation of squared distance and taking diving by n) basically mean haha, then we will get variance\n",
    "    '''Variance = Mean of Squared Distances'''\n",
    "    variance = np.mean(x_mu, axis=0)\n",
    "    std_dev = variance ** (1/2) # OR np.sqrt(variance)\n",
    "\n",
    "    return std_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb38964",
   "metadata": {},
   "source": [
    "#### Case 1: np.mean(X) (no axis)\n",
    "\n",
    "> np.mean(X)\n",
    "\n",
    "NumPy flattens everything:\n",
    "```python \n",
    "(2 + 4 + 6 + 1000 + 2000 + 3000) / 6 = 1002\n",
    "```\n",
    "\n",
    "One number.\n",
    "You just destroyed all structure.\n",
    "\n",
    "#### Case 2: axis=0 (THIS is the important one)\n",
    "\n",
    "> np.mean(X, axis=0)\n",
    "\n",
    "\n",
    "Think:\n",
    "\n",
    "> ‚ÄúFor each column, average down the rows‚Äù\n",
    "\n",
    "Column 0:\n",
    "```python \n",
    "(2 + 4 + 6) / 3 = 4\n",
    "```\n",
    "\n",
    "Column 1:\n",
    "```python \n",
    "(1000 + 2000 + 3000) / 3 = 2000\n",
    "```\n",
    "\n",
    "Result:\n",
    "```python \n",
    "[4, 2000]\n",
    "```\n",
    "\n",
    "üëâ One mean per feature\n",
    "\n",
    "#### Case 3: axis=1 (for contrast)\n",
    "\n",
    "> np.mean(X, axis=1)\n",
    "\n",
    "\n",
    "Think:\n",
    "\n",
    "> ‚ÄúFor each row, average across the columns‚Äù\n",
    "\n",
    "Row 0:\n",
    "```python \n",
    "(2 + 1000) / 2 = 501\n",
    "```\n",
    "\n",
    "Row 1:\n",
    "```python \n",
    "(4 + 2000) / 2 = 1002\n",
    "```\n",
    "\n",
    "Row 2:\n",
    "```python \n",
    "(6 + 3000) / 2 = 1503\n",
    "```\n",
    "\n",
    "Result:\n",
    "```python \n",
    "[501, 1002, 1503]\n",
    "```\n",
    "\n",
    "üëâ One mean per data point (useless for scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e338eb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "(20640, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.344766</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.628559</td>\n",
       "      <td>-0.153758</td>\n",
       "      <td>-0.974429</td>\n",
       "      <td>-0.049597</td>\n",
       "      <td>1.052548</td>\n",
       "      <td>-1.327835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.332238</td>\n",
       "      <td>-0.607019</td>\n",
       "      <td>0.327041</td>\n",
       "      <td>-0.263336</td>\n",
       "      <td>0.861439</td>\n",
       "      <td>-0.092512</td>\n",
       "      <td>1.043185</td>\n",
       "      <td>-1.322844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.782699</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>1.155620</td>\n",
       "      <td>-0.049016</td>\n",
       "      <td>-0.820777</td>\n",
       "      <td>-0.025843</td>\n",
       "      <td>1.038503</td>\n",
       "      <td>-1.332827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.932968</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>0.156966</td>\n",
       "      <td>-0.049833</td>\n",
       "      <td>-0.766028</td>\n",
       "      <td>-0.050329</td>\n",
       "      <td>1.038503</td>\n",
       "      <td>-1.337818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.012881</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>0.344711</td>\n",
       "      <td>-0.032906</td>\n",
       "      <td>-0.759847</td>\n",
       "      <td>-0.085616</td>\n",
       "      <td>1.038503</td>\n",
       "      <td>-1.337818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  2.344766  0.982143  0.628559  -0.153758   -0.974429 -0.049597  1.052548   \n",
       "1  2.332238 -0.607019  0.327041  -0.263336    0.861439 -0.092512  1.043185   \n",
       "2  1.782699  1.856182  1.155620  -0.049016   -0.820777 -0.025843  1.038503   \n",
       "3  0.932968  1.856182  0.156966  -0.049833   -0.766028 -0.050329  1.038503   \n",
       "4 -0.012881  1.856182  0.344711  -0.032906   -0.759847 -0.085616  1.038503   \n",
       "\n",
       "   Longitude  \n",
       "0  -1.327835  \n",
       "1  -1.322844  \n",
       "2  -1.332827  \n",
       "3  -1.337818  \n",
       "4  -1.337818  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now as we can see that the population is way larger, we need feature scaling, so that the gradient isnt affected largely cuz of one feature\n",
    "\n",
    "# since we will be using numpy operations, lets convert these data points into numpy values\n",
    "\n",
    "x_np = x.values\n",
    "y_np = y.values\n",
    "\n",
    "# writing the function for feature scaling (this is generally imported from sklearn) using our own std function for standard deviation\n",
    "def feature_scaling(X):\n",
    "    mu = np.mean(X, axis=0)       # mean per feature\n",
    "    sigma = std(X)     # std per feature\n",
    "    X_scaled = (X - mu) / sigma\n",
    "    return X_scaled, mu, sigma\n",
    "\n",
    "x_scaled_np, mu, sigma = feature_scaling(x_np)\n",
    "print(x_scaled_np.shape)\n",
    "print(x_scaled_np.shape)\n",
    "# scaled data with data frame\n",
    "columns = x.columns\n",
    "X_scaled_df = pd.DataFrame(x_scaled_np, columns=columns)\n",
    "X_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a0f9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function for a multiple linear regression:\n",
    "# the cost function would be similar to single linear regression, but the w will be replaced by w_vector and x will be replaced by x_vector.\n",
    "\n",
    "def compute_cost(x,y,w,b):\n",
    "    # here we will compute the cost J, using MSE on multi linear regression\n",
    "    m,n = x.shape\n",
    "    # for cost, first we need y_hat\n",
    "    y_hat = np.dot(x,w) + b\n",
    "    # then we need error\n",
    "    error = y_hat - y\n",
    "    # then we will calculate the MSE\n",
    "    j_wb = (1/(2*m))* (np.sum(error ** 2))\n",
    "\n",
    "    return j_wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6b53ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will compute the gradient but for an entire vector\n",
    "def compute_gradient(x,y,w,b):\n",
    "    # gradient is the PDE of w for weight, and wrt b for bias\n",
    "    # now as we know, that pde of J(w,b) w.r.t w => dj_dw = 1/m * (f_wb - y)*x\n",
    "    # same for b, without x => db_dw = 1/m * (f_wb - y)\n",
    "    m,n = x.shape\n",
    "    f_wb = np.dot(x,w) + b\n",
    "    error = f_wb - y\n",
    "    dj_dw = (1/m) * np.dot(x.T, error)\n",
    "    dj_db = (1/m) * np.sum(error)\n",
    "\n",
    "    return dj_dw, dj_db\n",
    "\n",
    "def gradient_descent(compute_cost, compute_gradient, x, y, w, b, alpha, num_iter):\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    b_history = []\n",
    "    for i in range(num_iter):\n",
    "        dj_dw, dj_db = compute_gradient(x,y,w,b)\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "        j_wb = compute_cost(x,y,w,b)\n",
    "        J_history.append(j_wb)\n",
    "        w_history.append(w)\n",
    "        b_history.append(b)\n",
    "    \n",
    "    return w,b, J_history,w_history ,b_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10fe4ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(2.7555948588377857), np.float64(2.706946835348318), np.float64(2.6592771724427453), np.float64(2.6125659364705407), np.float64(2.5667936076425444)]\n",
      "[np.float64(0.2621611560639754), np.float64(0.262161155456082), np.float64(0.2621611548487486), np.float64(0.26216115424197467), np.float64(0.26216115363575965)]\n",
      "[array([ 0.00793989,  0.00121882,  0.00175337, -0.00053889, -0.00028444,\n",
      "       -0.00027391, -0.00166351, -0.00053042]), array([ 0.01579443,  0.00243597,  0.0034711 , -0.00108035, -0.00056299,\n",
      "       -0.00054643, -0.00331087, -0.00106755]), array([ 0.02356459,  0.00365133,  0.00515382, -0.00162413, -0.00083571,\n",
      "       -0.00081757, -0.00494235, -0.0016112 ]), array([ 0.03125133,  0.00486477,  0.00680216, -0.00216994, -0.00110266,\n",
      "       -0.00108732, -0.00655817, -0.0021612 ]), array([ 0.03885562,  0.00607615,  0.00841673, -0.00271756, -0.00136392,\n",
      "       -0.00135569, -0.00815858, -0.00271735])]\n",
      "[array([ 0.83086176,  0.11902097, -0.2678063 ,  0.3075512 , -0.00442116,\n",
      "       -0.03937554, -0.89675571, -0.86755238]), array([ 0.83086122,  0.11902083, -0.26780532,  0.30755042, -0.0044212 ,\n",
      "       -0.03937552, -0.8967572 , -0.8675538 ]), array([ 0.83086067,  0.1190207 , -0.26780435,  0.30754964, -0.00442124,\n",
      "       -0.03937549, -0.89675868, -0.86755522]), array([ 0.83086013,  0.11902057, -0.26780338,  0.30754887, -0.00442128,\n",
      "       -0.03937547, -0.89676016, -0.86755664]), array([ 0.83085958,  0.11902043, -0.26780241,  0.30754809, -0.00442132,\n",
      "       -0.03937545, -0.89676164, -0.86755806])]\n"
     ]
    }
   ],
   "source": [
    "# now we will move to finding the w and b for multi linear regression:\n",
    "# input data: x_scaled_np\n",
    "# target values: y_np\n",
    "X = x_scaled_np\n",
    "y = y_np\n",
    "m,n = X.shape\n",
    "# initializing the w and b:\n",
    "w = np.zeros(n)\n",
    "b = 0\n",
    "w,b,J_history, w_history, b_history = gradient_descent(compute_cost, compute_gradient, X, y, w, b, 0.01, 10000)\n",
    "print(J_history[:5])\n",
    "print(J_history[-5:])\n",
    "print(w_history[:5])\n",
    "print(w_history[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d903f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.lineplot(J_history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d431da",
   "metadata": {},
   "source": [
    "### Split the data into train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "927f3dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd9e4496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20640\n",
      "[20294  8281   904 ...  1461  8429 16104]\n",
      "[17633 17183  2146 ... 16757 20174 17384]\n"
     ]
    }
   ],
   "source": [
    "# Now we will split the data:\n",
    "m = X.shape[0] # this gives the number of data points, in this case, house\n",
    "indices = np.random.permutation(m) # this is to just re-arange the data points if they were linearly arranged\n",
    "print(m) # 20640\n",
    "split = int(0.8*m) # 16512\n",
    "\n",
    "# actual split\n",
    "train_idx = indices[:split]\n",
    "test_idx  = indices[split:]\n",
    "\n",
    "print(train_idx) # random indexes assigned (80%)\n",
    "print(test_idx) # remaining 20%\n",
    "\n",
    "# assigning these indexes to the data\n",
    "x_train = X[train_idx]\n",
    "y_train = y[train_idx]\n",
    "\n",
    "x_test = X[test_idx]\n",
    "y_test = y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2196259b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.26044894555791126)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b,J_history, w_history, b_history = gradient_descent(compute_cost, compute_gradient, x_train, y_train, w, b, 0.01, 10000)\n",
    "train_cost = compute_cost(x_train, y_train, w, b)\n",
    "train_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4413996f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.36204221, 4.26927859, 0.99953866, ..., 2.3794016 , 2.79653023,\n",
       "       2.83149622], shape=(4128,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = np.dot(x_test, w) + b\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3790313d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.26967082003501636)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cost = compute_cost(x_test, y_test, w, b)\n",
    "test_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a781598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5393416400700327\n"
     ]
    }
   ],
   "source": [
    "mse = np.mean((y_test_pred-y_test)**2)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bcdc01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.5393416400700327\n",
      "RMSE: 0.7343988290227815\n",
      "MAE : 0.5331396392273271\n",
      "R¬≤  : 0.599917593225326\n"
     ]
    }
   ],
   "source": [
    "mse  = np.mean((y_test_pred - y_test) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "mae  = np.mean(np.abs(y_test_pred - y_test))\n",
    "\n",
    "ss_res = np.sum((y_test - y_test_pred) ** 2)\n",
    "ss_tot = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "r2 = 1 - ss_res / ss_tot\n",
    "\n",
    "print(\"MSE :\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE :\", mae)\n",
    "print(\"R¬≤  :\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
